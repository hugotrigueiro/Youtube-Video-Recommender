{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Dados Brutos\n",
    "Escolhendo as palavras-chave de pesquisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = []\n",
    "\n",
    "N_words = int(input(\"Digite a quantidade de palavras-chave que você deseja pesquisar: \"))\n",
    "x = 0\n",
    "while x < N_words:\n",
    "    search_word = str(input(\"Digite a palavra-chave nº\" + str((x+1)) + \" de pesquisa: \"))\n",
    "    search_words.append(search_word.replace(\" \", \"+\"))\n",
    "    x = x + 1\n",
    "\n",
    "N_pages = int(input(\"Digite a quantidade de páginas do Youtube para se pesquisar: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_url = \"https://www.youtube.com/results?search_query={}&p={}\"\n",
    "search_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_code = []\n",
    "urls_searched = []\n",
    "words_searched = []\n",
    "for word in search_words:\n",
    "    for page in range(1, (1+N_pages)):\n",
    "        url = search_url.format(word, page)\n",
    "        url_code = rq.get(url)\n",
    "        words_searched.append(word)\n",
    "        urls_searched.append(url)\n",
    "        urls_code.append(url_code.text)\n",
    "\n",
    "urls_searched = pd.Series(urls_searched)\n",
    "urls_code = pd.Series(urls_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_brutos = pd.DataFrame({\"urls\": urls_searched, \"code\": urls_code, \"query\": words_searched})\n",
    "dados_brutos.to_csv(\"dados_brutos.txt\", index=False)\n",
    "dados_brutos.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Processamento dos Dados\n",
    "Processando os dados para a extração dos campos de informação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "urls_videos = []\n",
    "pages_video = []\n",
    "queries = []\n",
    "\n",
    "for n, page in enumerate(dados_brutos[\"code\"].apply(BeautifulSoup)):\n",
    "    for link in page.findAll(\"a\"):\n",
    "        if link.has_attr(\"aria-describedby\") == True:\n",
    "            queries.append(dados_brutos[\"query\"].iloc[n])\n",
    "            titles.append(link[\"title\"])\n",
    "            urlls_videos = \"https://youtube.com.br\" + link[\"href\"]\n",
    "            urls_videos.append(urlls_videos)\n",
    "            pages_video.append(rq.get(urlls_videos).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"title\": titles, \"urls_videos\": urls_videos, \"query\": queries, \"pages\": pages_video})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"dados_processados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Coletando dados dos vídeos\n",
    "Processo de extração dos campos de informações das páginas de cada vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gots_datas = []\n",
    "for page in data[\"pages\"]:\n",
    "    parsed = BeautifulSoup(page, \"html.parser\")\n",
    "    \n",
    "    class_watch = parsed.find_all(attrs={\"class\":re.compile(r\"watch\")})\n",
    "    id_watch = parsed.find_all(attrs={\"id\":re.compile(r\"watch\")})\n",
    "    channel = parsed.find_all(\"a\", attrs={\"href\":re.compile(r\"channel\")})\n",
    "    meta = parsed.find_all(\"meta\")\n",
    "    \n",
    "    got_data = {}\n",
    "    \n",
    "    for cl in class_watch:\n",
    "        colname = \"_\".join(cl[\"class\"])\n",
    "        if \"clearfix\" in colname:\n",
    "            continue\n",
    "        got_data[colname] = cl.text.strip()\n",
    "    \n",
    "    for cl in id_watch:\n",
    "        colname = cl[\"id\"]\n",
    "        got_data[colname] = cl.text.strip()\n",
    "        \n",
    "    for cl in meta:\n",
    "        colname = cl.get(\"property\")\n",
    "        if colname is not None:\n",
    "            got_data[colname] = cl[\"content\"]\n",
    "    \n",
    "    for n, cl in enumerate(channel):\n",
    "        got_data[\"channel_link_{}\".format(n)] = cl[\"href\"]\n",
    "    \n",
    "    gots_datas.append(got_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_dict= {}\n",
    "for colname in gots_datas[0].keys():\n",
    "    adapt_dict[colname] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = list(pd.Series(gots_datas).apply(lambda x: pd.DataFrame(x, index=range(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data = pd.concat(all_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data.to_csv(\"dados_dos_videos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificação\n",
    "Verificação da extração correta dos dados e geração de uma base de informações limpa e adequada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = [\"watch-title\", \"watch-view-count\", \"watch-time-text\", \"content_watch-info-tag-list\", \"watch7-headline\",\n",
    "                   \"watch7-user-header\", \"watch8-sentiment-actions\", \"og:image\", \"og:image:width\", \"og:image:height\",\n",
    "                   \"og:description\", \"og:video:width\", \"og:video:height\", \"og:video:type\", \"channel_link_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data[selected_columns].to_csv(\"features_selecionadas(sem labels).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_data[selected_columns].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Preenchimento dos labels de interesse\n",
    "Após a etapa anterior, os labels de classficiação dos vídeos, caso seja do meu interesse ou não assistí-los, será preenchido manualmente através de uma planilha (Excel) no campo \"interested\", sendo marcados como: \n",
    "\n",
    "- **1:** tenho interesse em assistir aquele vídeo\n",
    "- **0:** não tenho interesse em assistir aquele vídeo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
